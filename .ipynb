{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "from yelpapi import YelpAPI\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7c3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(JSON_FILE,  delete_if_exists=False):\n",
    "    \n",
    "    ## Check if JSON_FILE exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    \n",
    "    ## If it DOES exist:\n",
    "    if file_exists == True:\n",
    "        \n",
    "        ## Check if user wants to delete if exists\n",
    "        if delete_if_exists==True:\n",
    "            \n",
    "            print(f\"[!] {JSON_FILE} already exists. Deleting previous file...\")\n",
    "            ## delete file and confirm it no longer exits.\n",
    "            os.remove(JSON_FILE)\n",
    "            ## Recursive call to function after old file deleted\n",
    "            create_json_file(JSON_FILE,delete_if_exists=False)\n",
    "        else:\n",
    "            print(f\"[i] {JSON_FILE} already exists.\")            \n",
    "            \n",
    "            \n",
    "    ## If it does NOT exist:\n",
    "    else:\n",
    "        \n",
    "        ## INFORM USER AND SAVE EMPTY LIST\n",
    "        print(f\"[i] {JSON_FILE} not found. Saving empty list to new file.\")\n",
    "        \n",
    "        ## CREATE ANY NEEDED FOLDERS\n",
    "        # Get the Folder Name only\n",
    "        folder = os.path.dirname(JSON_FILE)\n",
    "        \n",
    "        ## If JSON_FILE included a folder:\n",
    "        if len(folder)>0:\n",
    "            # create the folder\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "        ## Save empty list to start the json file\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c8c108",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Peach/Documents/Dojo-env/dojo-env-setup/Stack4/Week2/APICallEfficacy/.hidden/yelpi.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Peach\\Dropbox\\Dojo-env\\dojo-env-setup\\Stack4\\Week2\\APICallEfficacy\\.ipynb Cell 3\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Peach/Dropbox/Dojo-env/dojo-env-setup/Stack4/Week2/APICallEfficacy/.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m/Users/Peach/Documents/Dojo-env/dojo-env-setup/Stack4/Week2/APICallEfficacy/.hidden/yelpi.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Peach/Dropbox/Dojo-env/dojo-env-setup/Stack4/Week2/APICallEfficacy/.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     yl \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "File \u001b[1;32mc:\\Users\\Peach\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Peach/Documents/Dojo-env/dojo-env-setup/Stack4/Week2/APICallEfficacy/.hidden/yelpi.json'"
     ]
    }
   ],
   "source": [
    "with open('/Users/Peach/Documents/Dojo-env/dojo-env-setup/Stack4/Week2/APICallEfficacy/.hidden/yelpi.json', 'r') as f:\n",
    "    yl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ed7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_api = YelpAPI(yl['api-key'], timeout_s=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc  ='Chicago, IL',\n",
    "term ='Italian',\n",
    "cat  = 'Bistro'\n",
    "iterlim = 20\n",
    "radius = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bc287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying JSON_FILE filename (can include a folder)\n",
    "# include the search terms in the filename\n",
    "JSON_FILE = \"Data/results_in_progress_NY_pizza.json\"\n",
    "JSON_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990cc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if JSON_FILE exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "## If it does not exist: \n",
    "if file_exists == False:\n",
    "    \n",
    "    ## CREATE ANY NEEDED FOLDERS\n",
    "    # Get the Folder Name only\n",
    "    folder = os.path.dirname(JSON_FILE)\n",
    "    ## If JSON_FILE included a folder:\n",
    "    if len(folder)>0:\n",
    "        # create the folder\n",
    "        os.makedirs(folder,exist_ok=True)\n",
    "        \n",
    "        \n",
    "    ## INFORM USER AND SAVE EMPTY LIST\n",
    "    print(f'[i] {JSON_FILE} not found. Saving empty list to file.')\n",
    "    \n",
    "    \n",
    "    # save an empty list\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([],f)  \n",
    "# If it exists, inform user\n",
    "else:\n",
    "    print(f\"[i] {JSON_FILE} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17517686",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c50fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=loc,\n",
    "                                term=term,\n",
    "                                category=cat,\n",
    "                                limit=iterlim,\n",
    "                                radius=radius,\n",
    "                               offset=n_results)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2485cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many results total?\n",
    "total_results = results['total']\n",
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional packages for controlling our loop\n",
    "import time, math\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new results with old list with extend and save to file\n",
    "previous_results.extend(results['businesses'])  \n",
    "with open(JSON_FILE,'w') as f:\n",
    "     json.dump(previous_results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "for i in tqdm_notebook(range(n_pages)):\n",
    "    # adds 200 ms pause\n",
    "    time.sleep(.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bb900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    # add a 200ms pause\n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete file and confirm it no longer exits.\n",
    "os.remove(JSON_FILE)\n",
    "os.path.isfile(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new empty json file (exist the previous if it exists)\n",
    "create_json_file(JSON_FILE, delete_if_exists=True)\n",
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')\n",
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION,\n",
    "                                term=TERM,\n",
    "                               offset=n_results)\n",
    "## How many results total?\n",
    "total_results = results['total']\n",
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    \n",
    "    if (n_results + results_per_page) > 1000:\n",
    "        print('Exceeded 1000 api calls. Stopping loop.')\n",
    "        break\n",
    "    \n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    # display(previous_results)\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbcdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final results\n",
    "final_df = pd.read_json(JSON_FILE)\n",
    "display(final_df.head(), final_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate results\n",
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0bb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate ID's \n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop duplicate ids and confirm there are no more duplicates\n",
    "final_df = final_df.drop_duplicates(subset='id')\n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final results to a compressed csv\n",
    "final_df.to_csv('Data/final_results_NY_pizza.csv.gz', compression='gzip',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dojo-env",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
